{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dea6e513",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text-v2-moe:latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "19e30747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.035544503,\n",
       " 0.022141146,\n",
       " -0.0031282792,\n",
       " -0.053541426,\n",
       " -0.031493615,\n",
       " -0.035906337,\n",
       " 0.0048250337,\n",
       " 0.03290511,\n",
       " -0.0074005914,\n",
       " 0.018139986,\n",
       " -0.0033449966,\n",
       " -0.031072015,\n",
       " 0.059311315,\n",
       " -0.009700786,\n",
       " 0.011966846,\n",
       " -0.012304815,\n",
       " -0.02474464,\n",
       " 0.020620773,\n",
       " 0.020653537,\n",
       " 0.0045389133,\n",
       " 0.05094597,\n",
       " -0.053764988,\n",
       " 0.0028969122,\n",
       " -0.081011645,\n",
       " -0.0017085393,\n",
       " 0.012681573,\n",
       " 0.04951937,\n",
       " -0.041026734,\n",
       " 0.049410876,\n",
       " 0.041351516,\n",
       " -0.037418414,\n",
       " -0.038341247,\n",
       " 0.032251403,\n",
       " -0.011293073,\n",
       " -0.06353289,\n",
       " 0.05361984,\n",
       " 0.008099089,\n",
       " -0.014306246,\n",
       " 0.042595692,\n",
       " 0.06105853,\n",
       " 0.06772258,\n",
       " -0.0020974549,\n",
       " -0.00940951,\n",
       " 0.04918419,\n",
       " -0.011917762,\n",
       " 0.040059727,\n",
       " -0.016860534,\n",
       " 0.008396817,\n",
       " 0.031306956,\n",
       " -0.016937345,\n",
       " -0.024058364,\n",
       " -0.0040462697,\n",
       " 0.02981428,\n",
       " -0.026197536,\n",
       " 0.012938638,\n",
       " -0.054652676,\n",
       " 0.019943008,\n",
       " -0.040400233,\n",
       " 0.020883348,\n",
       " -0.033205096,\n",
       " -0.059710212,\n",
       " 0.0013596527,\n",
       " 0.083772294,\n",
       " -0.048477676,\n",
       " -0.037903875,\n",
       " -0.047012184,\n",
       " 0.016901985,\n",
       " 0.049351044,\n",
       " 0.012703092,\n",
       " -0.00088511995,\n",
       " -0.023944793,\n",
       " 0.0028348903,\n",
       " -0.02093301,\n",
       " -0.016051756,\n",
       " -0.06739152,\n",
       " -0.004066925,\n",
       " 0.008606997,\n",
       " 0.008966019,\n",
       " -0.01390261,\n",
       " 0.03189985,\n",
       " 0.0004697188,\n",
       " -0.0028913363,\n",
       " -0.027884245,\n",
       " 0.0070450003,\n",
       " -0.030100167,\n",
       " -0.068550766,\n",
       " 0.024925094,\n",
       " -0.005696814,\n",
       " -0.017795816,\n",
       " -0.007930334,\n",
       " 0.02027611,\n",
       " 0.014429875,\n",
       " -0.011599901,\n",
       " 0.041961554,\n",
       " 0.012288309,\n",
       " -0.011442253,\n",
       " -0.02315662,\n",
       " 0.03412682,\n",
       " -0.015235245,\n",
       " 0.007407961,\n",
       " -0.0025917112,\n",
       " 0.035136107,\n",
       " 0.04583109,\n",
       " 0.02320924,\n",
       " -0.035662375,\n",
       " -0.01678017,\n",
       " 0.07576039,\n",
       " 0.0024610437,\n",
       " 0.016786233,\n",
       " -0.006693198,\n",
       " -0.074288726,\n",
       " 0.025689134,\n",
       " -0.049255062,\n",
       " -0.0082206195,\n",
       " -0.008516365,\n",
       " -0.014613308,\n",
       " 0.0061524394,\n",
       " 0.023051867,\n",
       " -0.010261171,\n",
       " 0.034278356,\n",
       " -0.0078019667,\n",
       " 0.024622995,\n",
       " 0.0069025904,\n",
       " 0.004944385,\n",
       " 0.035002626,\n",
       " -0.028113877,\n",
       " -0.019889442,\n",
       " 0.06645976,\n",
       " 0.013441238,\n",
       " 0.061477087,\n",
       " 0.012655373,\n",
       " 0.029078536,\n",
       " 0.0020470018,\n",
       " -0.010873989,\n",
       " -0.02068733,\n",
       " -0.025028225,\n",
       " -0.0078364685,\n",
       " -0.06616505,\n",
       " -0.018394582,\n",
       " -0.00016803897,\n",
       " 0.006679202,\n",
       " -0.03318867,\n",
       " 0.046547394,\n",
       " 0.0061868457,\n",
       " -0.0011136753,\n",
       " 0.08108194,\n",
       " 0.039493397,\n",
       " 0.0196192,\n",
       " -0.01168521,\n",
       " 0.02096476,\n",
       " 0.008261935,\n",
       " -0.055730283,\n",
       " -0.12646078,\n",
       " 0.024119789,\n",
       " -0.014786627,\n",
       " 0.006776811,\n",
       " -0.023476109,\n",
       " -0.0227796,\n",
       " 0.026962476,\n",
       " 0.0032810522,\n",
       " 0.10066411,\n",
       " -0.07880739,\n",
       " -6.954017e-05,\n",
       " -0.010214705,\n",
       " -0.043456495,\n",
       " 0.040889632,\n",
       " -0.019625511,\n",
       " -0.016898835,\n",
       " 0.0139523875,\n",
       " -0.08290979,\n",
       " 0.036585107,\n",
       " 0.01722607,\n",
       " 0.02620932,\n",
       " 0.018333357,\n",
       " -0.0036027227,\n",
       " 0.060095865,\n",
       " -0.010252562,\n",
       " -0.043724794,\n",
       " 0.0022329523,\n",
       " -0.024973406,\n",
       " -0.016377315,\n",
       " -0.04333953,\n",
       " 0.037064712,\n",
       " 0.03324276,\n",
       " 0.03259665,\n",
       " -0.09381545,\n",
       " -0.018600052,\n",
       " 0.009238932,\n",
       " -0.060122848,\n",
       " 0.12587586,\n",
       " 0.007802304,\n",
       " 0.059505478,\n",
       " -0.0011154914,\n",
       " 0.04172812,\n",
       " -0.07007978,\n",
       " 0.0013127725,\n",
       " -0.0071164044,\n",
       " 0.04866099,\n",
       " 0.026624532,\n",
       " -0.0850629,\n",
       " -0.002723808,\n",
       " -0.027228953,\n",
       " 0.01208825,\n",
       " 0.014101642,\n",
       " -0.033227988,\n",
       " 0.0033462173,\n",
       " -0.008895843,\n",
       " 0.04254679,\n",
       " 0.0012925655,\n",
       " 0.05166293,\n",
       " -0.07411303,\n",
       " -0.041289173,\n",
       " -0.039208096,\n",
       " 0.03613446,\n",
       " 0.0044634845,\n",
       " 0.03205365,\n",
       " -0.0006742952,\n",
       " -0.041139383,\n",
       " 0.03506124,\n",
       " -0.011582679,\n",
       " 0.020952312,\n",
       " 0.041483473,\n",
       " 0.025059296,\n",
       " -0.014608646,\n",
       " 0.029654164,\n",
       " -0.0107650105,\n",
       " 0.037719734,\n",
       " -0.034868404,\n",
       " 0.03718069,\n",
       " -0.018027108,\n",
       " 0.04741763,\n",
       " -0.05420753,\n",
       " -0.039594483,\n",
       " 0.016458051,\n",
       " -0.03175574,\n",
       " 0.014573436,\n",
       " -0.013756156,\n",
       " -0.004317621,\n",
       " -0.014064004,\n",
       " 0.043298017,\n",
       " -0.03748976,\n",
       " -0.033579957,\n",
       " 0.025938094,\n",
       " 0.002771215,\n",
       " -0.0025860772,\n",
       " -0.023480013,\n",
       " 0.00956229,\n",
       " -0.037357423,\n",
       " -0.026248837,\n",
       " 0.04276594,\n",
       " -0.035973374,\n",
       " 0.0014689862,\n",
       " -0.07264453,\n",
       " -0.00019313536,\n",
       " 0.030003075,\n",
       " 0.06163503,\n",
       " 0.022238009,\n",
       " -0.021765225,\n",
       " 0.014325003,\n",
       " -0.02318348,\n",
       " -0.04025829,\n",
       " 0.018801603,\n",
       " 0.0066707004,\n",
       " 0.007114633,\n",
       " -0.023201376,\n",
       " 0.08086512,\n",
       " 0.03401669,\n",
       " 0.06746904,\n",
       " -0.039938837,\n",
       " 0.03413772,\n",
       " -0.013568157,\n",
       " -0.034954585,\n",
       " -0.0345434,\n",
       " 0.034532182,\n",
       " -0.022821989,\n",
       " 0.01892592,\n",
       " -0.089605466,\n",
       " 0.027258921,\n",
       " -0.06906098,\n",
       " -0.004086563,\n",
       " -0.04035935,\n",
       " 0.010376776,\n",
       " -0.022754898,\n",
       " 0.01034921,\n",
       " 0.08851264,\n",
       " 0.025561254,\n",
       " 0.03475261,\n",
       " -0.026884932,\n",
       " -0.026927289,\n",
       " 0.004622619,\n",
       " -0.00753695,\n",
       " 0.012092914,\n",
       " 0.0034753284,\n",
       " -0.039499946,\n",
       " 0.011745271,\n",
       " -0.03185502,\n",
       " 0.05884667,\n",
       " 0.055652924,\n",
       " 0.020747565,\n",
       " 0.0025155707,\n",
       " 0.012805742,\n",
       " -0.021620562,\n",
       " 0.019742316,\n",
       " -0.013615696,\n",
       " -0.00053385843,\n",
       " 0.060819816,\n",
       " 0.01183043,\n",
       " -0.0010756765,\n",
       " -0.008903205,\n",
       " 0.024635194,\n",
       " 0.04892986,\n",
       " -0.05045504,\n",
       " 0.044553984,\n",
       " -0.059320733,\n",
       " 0.046769846,\n",
       " 0.023281224,\n",
       " -0.025487911,\n",
       " 0.02326746,\n",
       " -0.014678532,\n",
       " 0.032363866,\n",
       " 0.0006884808,\n",
       " -0.0006116479,\n",
       " -0.01100183,\n",
       " 0.023288425,\n",
       " -0.01335735,\n",
       " 0.05195435,\n",
       " -0.011846732,\n",
       " -0.017191118,\n",
       " 0.024020335,\n",
       " -0.016817406,\n",
       " 0.006602083,\n",
       " -0.02438065,\n",
       " 0.02221956,\n",
       " 0.024705796,\n",
       " -0.017827528,\n",
       " -0.055776644,\n",
       " -0.0109585365,\n",
       " 0.057626538,\n",
       " 0.050513316,\n",
       " 0.025863089,\n",
       " -0.0698722,\n",
       " 0.0023688872,\n",
       " 0.033528686,\n",
       " 0.025286285,\n",
       " 0.09658815,\n",
       " -0.0405482,\n",
       " -0.007187867,\n",
       " 0.0058224886,\n",
       " -0.04016995,\n",
       " 0.030412793,\n",
       " -0.014431368,\n",
       " 0.077023,\n",
       " 0.04202593,\n",
       " 0.05906487,\n",
       " 0.02468871,\n",
       " 0.008445716,\n",
       " 0.089990675,\n",
       " -0.04946436,\n",
       " -0.0056919903,\n",
       " -0.09895762,\n",
       " -0.044482283,\n",
       " -0.029497003,\n",
       " -0.012166869,\n",
       " 0.03854996,\n",
       " 0.020851655,\n",
       " 0.010740862,\n",
       " 0.041764017,\n",
       " -0.057609115,\n",
       " -0.006873819,\n",
       " -0.026663685,\n",
       " 0.013436237,\n",
       " 0.0038159683,\n",
       " -0.0018363144,\n",
       " -0.0416859,\n",
       " -0.013976407,\n",
       " 0.011411657,\n",
       " 0.029117728,\n",
       " -0.01869805,\n",
       " 0.005004945,\n",
       " 0.023543064,\n",
       " 0.028854629,\n",
       " 0.0038494787,\n",
       " 0.031387407,\n",
       " -0.009932056,\n",
       " -0.04083015,\n",
       " 0.075500816,\n",
       " 0.024421249,\n",
       " 0.047412388,\n",
       " -0.004462989,\n",
       " 0.016063172,\n",
       " -0.09949387,\n",
       " 0.0010921138,\n",
       " 0.015028767,\n",
       " -0.043255236,\n",
       " -0.020849725,\n",
       " -0.031842906,\n",
       " 0.02178132,\n",
       " 0.0020667883,\n",
       " 0.05786817,\n",
       " -0.023405395,\n",
       " -0.026373012,\n",
       " 0.014612087,\n",
       " -0.050113875,\n",
       " 0.010777274,\n",
       " -0.0048547583,\n",
       " -0.016437022,\n",
       " -0.056465365,\n",
       " -0.031754963,\n",
       " -0.01042056,\n",
       " 0.0077006537,\n",
       " -0.028307652,\n",
       " -0.006320446,\n",
       " 0.027759863,\n",
       " 0.0014687554,\n",
       " 0.0073023876,\n",
       " 0.0042866897,\n",
       " -0.022489775,\n",
       " 0.03759651,\n",
       " 0.032508157,\n",
       " -0.026691077,\n",
       " 0.021477442,\n",
       " 0.0048560235,\n",
       " -0.019801315,\n",
       " 0.0010422792,\n",
       " 0.024347544,\n",
       " 0.022254081,\n",
       " -0.048455354,\n",
       " 0.040092308,\n",
       " -0.00014476191,\n",
       " -0.0011688354,\n",
       " -0.019417351,\n",
       " -0.024902405,\n",
       " -0.06278691,\n",
       " 0.012280578,\n",
       " 0.06552752,\n",
       " -0.034211207,\n",
       " 0.0031861828,\n",
       " -0.09388643,\n",
       " 0.019053346,\n",
       " 0.052509937,\n",
       " -0.061074253,\n",
       " -0.020928219,\n",
       " -0.0020221937,\n",
       " 0.004821551,\n",
       " -0.07459557,\n",
       " 0.018301481,\n",
       " 0.0013981995,\n",
       " 0.0026407482,\n",
       " 0.048743714,\n",
       " -0.023940284,\n",
       " 0.0029536593,\n",
       " 0.014876709,\n",
       " -0.036973726,\n",
       " -0.02944868,\n",
       " -0.017860312,\n",
       " -0.011578934,\n",
       " 0.031142898,\n",
       " 0.0019831262,\n",
       " 0.008831516,\n",
       " 0.09152181,\n",
       " 0.0039194124,\n",
       " 0.027816132,\n",
       " -0.0035230056,\n",
       " -0.026503643,\n",
       " -0.027994841,\n",
       " 0.026229806,\n",
       " -0.018821836,\n",
       " 0.012646371,\n",
       " -0.06561843,\n",
       " 0.022105271,\n",
       " 0.015038126,\n",
       " -0.02887835,\n",
       " -0.024624785,\n",
       " 0.010977853,\n",
       " 0.020393562,\n",
       " -0.024386974,\n",
       " -0.017912794,\n",
       " 0.08821046,\n",
       " 0.011322723,\n",
       " -0.03925552,\n",
       " 0.009663981,\n",
       " 0.0028120955,\n",
       " -0.024332114,\n",
       " 0.019054795,\n",
       " 0.03211107,\n",
       " 0.040380407,\n",
       " 0.013954546,\n",
       " -0.009064492,\n",
       " 0.033538867,\n",
       " -0.020595491,\n",
       " 0.043915905,\n",
       " 0.040279564,\n",
       " -9.396619e-05,\n",
       " -0.00822817,\n",
       " -0.10892356,\n",
       " 0.03837749,\n",
       " -0.021868967,\n",
       " 0.013884998,\n",
       " -0.0051197484,\n",
       " 0.013448553,\n",
       " -0.001403578,\n",
       " 0.014817115,\n",
       " -0.028416265,\n",
       " -0.013213024,\n",
       " -0.08636068,\n",
       " -0.046205368,\n",
       " -0.011921097,\n",
       " -0.07480774,\n",
       " 0.056649163,\n",
       " -0.017328044,\n",
       " 0.050089926,\n",
       " -0.00078518724,\n",
       " -0.0058705513,\n",
       " -0.057081904,\n",
       " 0.08584885,\n",
       " -0.021899853,\n",
       " -0.006929567,\n",
       " -0.06019304,\n",
       " -0.09129099,\n",
       " -0.001986824,\n",
       " 0.010285066,\n",
       " 0.017453814,\n",
       " -0.046387028,\n",
       " -0.009899848,\n",
       " 0.039340265,\n",
       " 0.0047233575,\n",
       " -0.059799843,\n",
       " -0.07155717,\n",
       " 0.0013108144,\n",
       " -0.016942631,\n",
       " -0.07652913,\n",
       " 0.06220167,\n",
       " -0.03317724,\n",
       " 0.013260541,\n",
       " -0.08278413,\n",
       " -0.008672864,\n",
       " 0.011973948,\n",
       " -0.0504376,\n",
       " 0.00128537,\n",
       " 0.021829372,\n",
       " 0.01640377,\n",
       " -0.023347432,\n",
       " -0.023499426,\n",
       " 0.029808607,\n",
       " 0.028576449,\n",
       " -0.017503291,\n",
       " -0.008810054,\n",
       " -0.06283635,\n",
       " -0.007786557,\n",
       " 0.018208615,\n",
       " -0.028686665,\n",
       " 0.01962066,\n",
       " -0.012360717,\n",
       " -0.03247544,\n",
       " 0.0033237373,\n",
       " -0.011992292,\n",
       " -0.058337163,\n",
       " 0.029753523,\n",
       " -0.04545541,\n",
       " -0.056713484,\n",
       " -0.042878203,\n",
       " 0.055377614,\n",
       " 0.00413482,\n",
       " 0.017893082,\n",
       " -0.0054867566,\n",
       " -0.03897993,\n",
       " -0.008877155,\n",
       " -0.01992358,\n",
       " -0.022873443,\n",
       " 0.042273924,\n",
       " -0.062440123,\n",
       " 0.0015348216,\n",
       " 0.010984401,\n",
       " 0.060278967,\n",
       " 0.025979552,\n",
       " -0.026496595,\n",
       " 0.045318864,\n",
       " -0.0068962458,\n",
       " 0.026473792,\n",
       " -0.06402574,\n",
       " 0.027521344,\n",
       " -0.014662236,\n",
       " 0.037674908,\n",
       " 0.003454786,\n",
       " -0.047305167,\n",
       " -0.053055927,\n",
       " 0.0007206689,\n",
       " 0.030329023,\n",
       " 0.083750956,\n",
       " 0.04991925,\n",
       " -0.024944752,\n",
       " 0.0010489614,\n",
       " -0.04405365,\n",
       " -0.02584257,\n",
       " -0.017801575,\n",
       " -0.006910315,\n",
       " -0.016518768,\n",
       " -0.048953973,\n",
       " -0.008281354,\n",
       " -0.013511397,\n",
       " 0.04396402,\n",
       " 0.044864785,\n",
       " 0.027800215,\n",
       " 0.013964496,\n",
       " 0.0065953736,\n",
       " -0.0097594075,\n",
       " 0.016347047,\n",
       " 0.024618538,\n",
       " -0.030014865,\n",
       " 0.003016087,\n",
       " 0.018439578,\n",
       " -0.026469471,\n",
       " -0.027692594,\n",
       " 0.015909908,\n",
       " -0.011235809,\n",
       " -0.011176384,\n",
       " 0.032431506,\n",
       " -0.018443836,\n",
       " -0.050661337,\n",
       " 0.028531704,\n",
       " 0.008742403,\n",
       " 0.04597341,\n",
       " -0.0257022,\n",
       " 0.0091251135,\n",
       " 0.004184854,\n",
       " -0.025901627,\n",
       " -0.006296371,\n",
       " -0.017754562,\n",
       " -0.015812999,\n",
       " -0.015531051,\n",
       " 0.054653738,\n",
       " 0.025395254,\n",
       " 0.033976775,\n",
       " -0.015778776,\n",
       " -0.059659727,\n",
       " 0.0052879127,\n",
       " -0.036232572,\n",
       " 0.025106212,\n",
       " 0.06358397,\n",
       " -0.0073844995,\n",
       " 0.024830667,\n",
       " 0.0033627814,\n",
       " 0.005081138,\n",
       " 0.102344915,\n",
       " 0.008861683,\n",
       " -0.01089373,\n",
       " -0.0007126033,\n",
       " 0.07106871,\n",
       " -0.06570514,\n",
       " -0.033495657,\n",
       " 0.028077058,\n",
       " -0.005298628,\n",
       " -0.06254674,\n",
       " 0.02772988,\n",
       " 0.011765423,\n",
       " -0.016659148,\n",
       " 0.0008082471,\n",
       " 0.026169823,\n",
       " 0.048364505,\n",
       " 0.016525254,\n",
       " -0.01571253,\n",
       " 0.055428013,\n",
       " -0.014103013,\n",
       " 0.018097457,\n",
       " 0.03629677,\n",
       " 0.036088265,\n",
       " 0.020273386,\n",
       " 0.03296444,\n",
       " -0.022679947,\n",
       " 0.0031153786,\n",
       " 0.07944439,\n",
       " 0.0051896186,\n",
       " 0.015996588,\n",
       " 0.0067996886,\n",
       " 0.05637996,\n",
       " -0.027086614,\n",
       " 0.0310012,\n",
       " -0.03499983,\n",
       " 0.0046730693,\n",
       " -0.020557638,\n",
       " 0.030191999,\n",
       " 0.0018810381,\n",
       " -0.045844797,\n",
       " 0.0057460237,\n",
       " -0.026702186,\n",
       " 0.0009283396,\n",
       " 0.0004250746,\n",
       " -0.028938742,\n",
       " -0.06373497,\n",
       " -0.0009791902,\n",
       " -0.055454902,\n",
       " -0.017054318,\n",
       " -0.022482906,\n",
       " 0.013176477,\n",
       " 0.00033769605,\n",
       " 0.057412792,\n",
       " 0.01129563,\n",
       " -0.056206208,\n",
       " 0.006242936,\n",
       " -0.03346463,\n",
       " 0.051361185,\n",
       " 0.011368967,\n",
       " -0.079733886,\n",
       " -0.019575547,\n",
       " -0.052478578,\n",
       " -0.012975725,\n",
       " -0.053337626,\n",
       " -0.04278765,\n",
       " -0.018089686,\n",
       " -0.018403696,\n",
       " 0.0045204978,\n",
       " 0.056034423,\n",
       " 0.03002929,\n",
       " 0.07435004,\n",
       " -0.030253567,\n",
       " 0.0030503573,\n",
       " -0.008030249,\n",
       " 0.029001473,\n",
       " -0.030887542,\n",
       " -0.014940678,\n",
       " 0.06219711,\n",
       " 0.0009802037,\n",
       " 0.0072825826,\n",
       " 0.05249578,\n",
       " 0.041813746,\n",
       " -0.029892357,\n",
       " -0.0049996804,\n",
       " 0.010339653,\n",
       " 0.04190519,\n",
       " 0.0493803,\n",
       " -0.019138984,\n",
       " -0.006616461,\n",
       " 0.017991468,\n",
       " 0.023356559,\n",
       " 0.0033708583,\n",
       " -0.02823695,\n",
       " 0.020341214,\n",
       " -0.047864564,\n",
       " 0.054957792,\n",
       " 0.02584278,\n",
       " -0.016115122,\n",
       " 0.10143849,\n",
       " -0.033474024,\n",
       " -0.009983847,\n",
       " -0.008457001,\n",
       " -0.018569745,\n",
       " -0.028266305,\n",
       " 0.07438936,\n",
       " -0.009451936,\n",
       " 0.021868123,\n",
       " -0.035474967,\n",
       " 0.022288235,\n",
       " 0.001609582,\n",
       " -0.02135454,\n",
       " -0.022791812,\n",
       " 0.014847859,\n",
       " 0.040888175,\n",
       " 0.028264932,\n",
       " 0.009522714,\n",
       " -0.09657508,\n",
       " -0.048280198,\n",
       " 0.0064668963,\n",
       " 0.030463105,\n",
       " -0.032909047,\n",
       " 0.000549122,\n",
       " -0.07508653,\n",
       " -0.025434334,\n",
       " 0.04947474]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = embeddings.embed_query(\"Hello, world!\")\n",
    "vector.__len__()\n",
    "\n",
    "len(vector)\n",
    "\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c996a7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "dimensions = 768\n",
    "index = faiss.IndexFlatL2(dimensions)\n",
    "\n",
    "vector_store = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "071f55f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'producer': 'pdfTeX-1.40.25',\n",
      " 'creator': 'LaTeX with hyperref',\n",
      " 'creationdate': '2025-04-29T01:11:16+00:00',\n",
      " 'author': '',\n",
      " 'keywords': '',\n",
      " 'moddate': '2025-04-29T01:11:16+00:00',\n",
      " 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live '\n",
      "                    '2023) kpathsea version 6.3.5',\n",
      " 'subject': '',\n",
      " 'title': '',\n",
      " 'trapped': '/False',\n",
      " 'source': './Mem0.pdf',\n",
      " 'total_pages': 23,\n",
      " 'page': 0,\n",
      " 'page_label': '1'}\n",
      "\n",
      "Mem0: Building Production-Ready AI Agents with\n",
      "Scalable Long-Term Memory\n",
      "Prateek Chhikara, Dev Khant, Saket Aryan, Taranjeet Singh,and Deshraj Yadav\n",
      "research@mem0.ai\n",
      "Large Language Models (LLMs) have demonstrated remarkable prowess in generating contextually coherent\n",
      "responses, yet their fixed context windows pose fundamental challenges for maintaining consistency over\n",
      "prolonged multi-session dialogues. We introduceMem0, a scalable memory-centric architecture that addresses\n",
      "this issue by dynamically extracting, consolidating, and retrieving salient information from ongoing conver-\n",
      "sations. Building on this foundation, we further propose an enhanced variant that leverages graph-based\n",
      "memory representations to capture complex relational structures among conversational elements. Through\n",
      "comprehensive evaluations on theLOCOMO benchmark, we systematically compare our approaches against six\n",
      "baseline categories: (i) established memory-augmented systems, (ii) retrieval-augmented generation (RAG)\n",
      "with varying chunk sizes andk-values, (iii) a full-context approach that processes the entire conversation\n",
      "history, (iv) an open-source memory solution, (v) a proprietary model system, and (vi) a dedicated memory\n",
      "management platform. Empirical results demonstrate that our methods consistently outperform all existing\n",
      "memory systems across four question categories: single-hop, temporal, multi-hop, and open-domain. No-\n",
      "tably, Mem0 achieves 26% relative improvements in the LLM-as-a-Judge metric over OpenAI, whileMem0 with\n",
      "graph memory achieves around 2% higher overall score than the baseMem0 configuration. Beyond accuracy\n",
      "gains, we also markedly reduce computational overhead compared to the full-context approach. In particular,\n",
      "Mem0 attains a 91% lower p95 latency and saves more than 90% token cost, thereby offering a compelling\n",
      "balance between advanced reasoning capabilities and practical deployment constraints. Our findings highlight\n",
      "the critical role of structured, persistent memory mechanisms for long-term conversational coherence, paving\n",
      "the way for more reliable and efficient LLM-driven AI agents.\n",
      "Code can be found at: https://mem0.ai/research\n",
      "1. Introduction\n",
      "Human memory is afoundation of intelligence—it shapes our identity, guides decision-making, and enables\n",
      "us to learn, adapt, and form meaningful relationships (Craik and Jennings, 1992). Among its many roles,\n",
      "memory is essential for communication: we recall past interactions, infer preferences, and construct evolving\n",
      "mental models of those we engage with (Assmann, 2011). This ability to retain and retrieve information\n",
      "over extended periods enables coherent, contextually rich exchanges that span days, weeks, or even months.\n",
      "AI agents, powered by large language models (LLMs), have made remarkable progress in generating fluent,\n",
      "contextually appropriate responses (Yu et al., 2024, Zhang et al., 2024). However, these systems are\n",
      "fundamentally limited by their reliance on fixed context windows, which severely restrict their ability to\n",
      "maintain coherence over extended interactions (Bulatov et al., 2022, Liu et al., 2023). This limitation stems\n",
      "from LLMs’ lack of persistent memory mechanisms that can extend beyond their finite context windows.\n",
      "While humans naturally accumulate and organize experiences over time, forming a continuous narrative\n",
      "arXiv:2504.19413v1  [cs.CL]  28 Apr 2025\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "file_path = \"./Mem0.pdf\"\n",
    "loader = PyPDFLoader(file_path, mode=\"page\")\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "pprint.pp(docs[0].metadata)\n",
    "\n",
    "print()\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c8dd220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53114682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id1',\n",
       " 'id2',\n",
       " 'id3',\n",
       " 'id4',\n",
       " 'id5',\n",
       " 'id6',\n",
       " 'id7',\n",
       " 'id8',\n",
       " 'id9',\n",
       " 'id10',\n",
       " 'id11',\n",
       " 'id12',\n",
       " 'id13',\n",
       " 'id14',\n",
       " 'id15',\n",
       " 'id16',\n",
       " 'id17',\n",
       " 'id18',\n",
       " 'id19',\n",
       " 'id20',\n",
       " 'id21',\n",
       " 'id22',\n",
       " 'id23']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add_documents(\n",
    "    documents=docs, ids=[f\"id{num + 1}\" for num in range(0, len(docs))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3ac7964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory\n",
      "Table 1:Performance comparison of memory-enabled systems across different question types in theLOCOMO dataset.\n",
      "Evaluation metrics include F1 score (F1), BLEU-1 (B1), and LLM-as-a-Judge score (J), with higher values indicating\n",
      "better performance.A-Mem∗ represents results from our re-run of A-Mem to generate LLM-as-a-Judge scores by setting\n",
      "temperature as 0.Mem0g indicates our proposed architecture enhanced with graph memory.Bold denotes the best\n",
      "performance for each metric across all methods. (↑) represents higher score is better.\n",
      "Method Single Hop Multi-Hop Open Domain Temporal\n",
      "F1 ↑ B1 ↑ J↑ F1 ↑ B1 ↑ J↑ F1 ↑ B1 ↑ J↑ F1 ↑ B1 ↑ J↑\n",
      "LoCoMo 25.02 19.75 – 12.04 11.16 – 40.36 29.05 – 18.41 14.77 –\n",
      "ReadAgent 9.15 6.48 – 5.31 5.12 – 9.67 7.66 – 12.60 8.87 –\n",
      "MemoryBank5.00 4.77 – 5.56 5.94 – 6.61 5.16 – 9.68 6.99 –\n",
      "MemGPT 26.65 17.72 – 9.15 7.44 – 41.04 34.34 – 25.52 19.44 –\n",
      "A-Mem 27.02 20.09 – 12.14 12.00 – 44.65 37.06 – 45.85 36.67 –\n",
      "A-Mem* 20.76 14.90 39.79±0.38 9.22 8.81 18.85±0.31 33.34 27.58 54.05±0.22 35.40 31.08 49.91±0.31\n",
      "LangMem 35.51 26.86 62.23±0.75 26.0422.3247.92±0.47 40.91 33.63 71.12±0.20 30.75 25.84 23.43±0.39\n",
      "Zep 35.74 23.30 61.70±0.32 19.37 14.82 41.35±0.48 49.5638.9276.60±0.13 42.00 34.53 49.31±0.50\n",
      "OpenAI 34.30 23.72 63.79±0.46 20.09 15.42 42.92±0.63 39.31 31.16 62.29±0.12 14.04 11.25 21.71±0.20\n",
      "Mem0 38.72 27.13 67.13±0.6528.6421.5851.15±0.31 47.65 38.72 72.93±0.11 48.9340.5155.51±0.34\n",
      "Mem0g 38.09 26.03 65.71±0.45 24.32 18.82 47.19±0.67 49.2740.3075.71±0.21 51.5540.2858.13±0.44\n",
      "text. These generated memories are then used as complete context for answering questions about each\n",
      "conversation, intentionally granting the OpenAI approach privileged access to all memories rather than\n",
      "only question-relevant ones. This methodology accommodates the lack of external API access for selective\n",
      "memory retrieval in OpenAI’s system for benchmarking.\n",
      "MemoryProviders WeincorporateZep(Rasmussenetal.,2025),amemorymanagementplatformdesigned\n",
      "for AI agents. Using their platform version, we conduct systematic evaluations across theLOCOMO dataset,\n",
      "maintaining temporal fidelity by preserving timestamp information alongside conversational content. This\n",
      "temporalanchoringensuresthattime-sensitivequeriescanbeaddressedthroughappropriatelycontextualized\n",
      "memory retrieval, particularly important for evaluating questions that require chronological awareness.\n",
      "This baseline represents an important commercial implementation of memory management specifically\n",
      "engineered for AI agents.\n",
      "4. Evaluation Results, Analysis and Discussion.\n",
      "4.1. Performance Comparison Across Memory-Enabled Systems\n",
      "Table1reportsF 1, B1 andJscoresforourtwoarchitectures— Mem0and Mem0g —againstasuiteofcompetitive\n",
      "baselines, asmentionedinSection3, onsingle -hop, multi-hop, open-domain, andtemporalquestions. Overall,\n",
      "both of our models set new state-of-the-art marks in all the three evaluation metrics for most question types.\n",
      "Single-Hop Question Performance Single-hop queries involve locating a single factual span contained\n",
      "within one dialogue turn. Leveraging its dense memories in natural language text,Mem0 secures the strongest\n",
      "results:F1=38.72, B1=27.13, and J=67.13. Augmenting the natural language memories with graph memory\n",
      "(Mem0g) yields marginal performance drop compared toMem0, indicating that relational structure provides\n",
      "limited utility when the retrieval target occupies a single turn. Among the existing baselines, the full-context\n",
      "OpenAIrun attains the next-best J score, reflecting the benefits of retaining the entire conversation in context,\n",
      "while LangMem and Zep both score around 8% relatively less against our models on J score. PreviousLOCOMO\n",
      "9\n",
      "Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory\n",
      "B. Algorithm\n",
      "Algorithm 1Memory Management System: Update Operations\n",
      "1: Input: Set of retrieved memoriesF, Existing memory storeM = {m1, m2, . . . , mn}\n",
      "2: Output: Updated memory storeM′\n",
      "3: procedure Up dat e M e mory(F, M)\n",
      "4: for each fact f ∈ F do\n",
      "5: operation ← C l as s i f y Op e r at ion(f , M) ▷ Execute appropriate operation based on\n",
      "classification\n",
      "6: if operation = ADDthen\n",
      "7: id ← GenerateUniqueID()\n",
      "8: M ← M ∪ {(id, f ,\"ADD\")} ▷ Add new fact with unique identifier\n",
      "9: else if operation = UPDATEthen\n",
      "10: mi ← FindRelatedMemory(f , M)\n",
      "11: if InformationContent(f ) > InformationContent(mi)then\n",
      "12: M ← (M \\ {mi})∪ {(idi, f ,\"UPDATE\")} ▷ Replace with richer information\n",
      "13: end if\n",
      "14: else if operation = DELETE then\n",
      "15: mi ← FindContradictedMemory(f , M)\n",
      "16: M ← M \\ {mi} ▷ Remove contradicted information\n",
      "17: else if operation = NOOPthen\n",
      "18: No operation performed ▷ Fact already exists or is irrelevant\n",
      "19: end if\n",
      "20: end for\n",
      "21: return M\n",
      "22: end procedure\n",
      "23: function C l as s i f y Op e r at ion( f , M)\n",
      "24: if ¬SemanticallySimilar(f , M)then\n",
      "25: return ADD ▷ New information not present in memory\n",
      "26: else ifContradicts(f , M)then\n",
      "27: return DELETE ▷ Information conflicts with existing memory\n",
      "28: else ifAugments(f , M)then\n",
      "29: return UPDATE ▷ Enhances existing information in memory\n",
      "30: else\n",
      "31: return NOOP ▷ No change required\n",
      "32: end if\n",
      "33: end function\n",
      "C. Selected Baselines\n",
      "LoCoMo The LoCoMo framework implements a sophisticated memory pipeline that enables LLM agents to\n",
      "maintain coherent, long-term conversations. At its core, the system divides memory into short-term and\n",
      "long-term components. After each conversation session, agents generate summaries (stored as short-term\n",
      "memory) that distill key information from that interaction. Simultaneously, individual conversation turns are\n",
      "21\n",
      "Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory\n",
      "Table 2:Performance comparison of various baselines with proposed methods. Latency measurements show p50\n",
      "(median) and p95 (95th percentile) values in seconds for both search time (time taken to fetch memories/chunks) and\n",
      "total time (time to generate the complete response). Overall LLM-as-a-Judge score (J) represents the quality metric of\n",
      "the generated responses on the entireLOCOMO dataset.\n",
      "Method\n",
      "Latency (seconds) Overall\n",
      "JSearch Total\n",
      "K chunk size/\n",
      "memory tokens p50 p95 p50 p95\n",
      "RAG\n",
      "1\n",
      "128 0.281 0.823 0.774 1.825 47.77 ± 0.23%\n",
      "256 0.251 0.710 0.745 1.628 50.15 ± 0.16%\n",
      "512 0.240 0.639 0.772 1.710 46.05 ± 0.14%\n",
      "1024 0.240 0.723 0.821 1.957 40.74 ± 0.17%\n",
      "2048 0.255 0.752 0.996 2.182 37.93 ± 0.12%\n",
      "4096 0.254 0.719 1.093 2.711 36.84 ± 0.17%\n",
      "8192 0.279 0.838 1.396 4.416 44.53 ± 0.13%\n",
      "2\n",
      "128 0.267 0.624 0.766 1.829 59.56 ± 0.19%\n",
      "256 0.255 0.699 0.802 1.907 60.97 ± 0.20%\n",
      "512 0.247 0.746 0.829 1.729 58.19 ± 0.18%\n",
      "1024 0.238 0.702 0.860 1.850 50.68 ± 0.13%\n",
      "2048 0.261 0.829 1.101 2.791 48.57 ± 0.22%\n",
      "4096 0.266 0.944 1.451 4.822 51.79 ± 0.15%\n",
      "8192 0.288 1.124 2.312 9.942 60.53 ± 0.16%\n",
      "Full-context 26031 - - 9.870 17.117 72.90 ± 0.19%\n",
      "A-Mem 2520 0.668 1.485 1.410 4.374 48.38 ± 0.15%\n",
      "LangMem 127 17.99 59.82 18.53 60.40 58.10 ± 0.21%\n",
      "Zep 3911 0.513 0.778 1.292 2.926 65.99 ± 0.16%\n",
      "OpenAI 4437 - - 0.466 0.889 52.90 ± 0.14%\n",
      "Mem0 1764 0.148 0.200 0.708 1.440 66.88 ± 0.15%\n",
      "Mem0g 3616 0.476 0.657 1.091 2.590 68.44 ± 0.17%\n",
      "expected relational advantages ofMem0g do not translate into better outcomes here, suggesting potential\n",
      "overhead or redundancy when navigating more intricate graph structures in multi-step reasoning scenarios.\n",
      "In temporal reasoning, Mem0g substantially outperforms other methods, validating that structured\n",
      "relational graphs excel in capturing chronological relationships and event sequences. The presence of explicit\n",
      "relational context significantly enhancesMem0g’s temporal coherence, outperformingMem0’s dense memory\n",
      "storage and highlighting the importance of precise relational representations when tracking temporally\n",
      "sensitive information. Open-domain performance further reinforces the value of relational modeling.Mem0g,\n",
      "benefiting from the relational clarity of graph-based memory, closely competes with the top-performing\n",
      "baseline (Zep). This competitive result underscoresMem0g’s robustness in integrating external knowledge\n",
      "through relational clarity, suggesting an optimal synergy between structured memory and open-domain\n",
      "information synthesis.\n",
      "11\n",
      "Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory\n",
      "robustframeworkforevaluatingtheeffectivenessofdifferentmemoryarchitecturesacrossvariousdimensions,\n",
      "including factual accuracy, computational efficiency, and scalability to extended conversations. Where\n",
      "applicable, unless otherwise specified, we set the temperature to 0 to ensure the runs are as reproducible as\n",
      "possible.\n",
      "Established LOCOMO Benchmarks We first establish a comparative foundation by evaluating previously\n",
      "benchmarked methods on theLOCOMO dataset. These include five established approaches: LoCoMo (Maha-\n",
      "rana et al., 2024), ReadAgent (Lee et al., 2024), MemoryBank (Zhong et al., 2024), MemGPT (Packer et al.,\n",
      "2023), and A-Mem (Xu et al., 2025). These established benchmarks not only provide direct comparison\n",
      "points with published results but also represent the evolution of conversational memory architectures across\n",
      "different algorithmic paradigms. For our evaluation, we select the metrics wheregpt-4o-mini was used\n",
      "for the evaluation. More details about these benchmarks are mentioned in Appendix C.\n",
      "Open-Source Memory Solutions Our second category consists of promising open-source memory architec-\n",
      "tures such as LangMem2 (Hot Path) that have demonstrated effectiveness in related conversational tasks but\n",
      "have not yet been evaluated on theLOCOMO dataset. By adapting these systems to our evaluation framework,\n",
      "we broaden the comparative landscape and identify potential alternative approaches that may offer competi-\n",
      "tive performance. We initialized the LLM withgpt-4o-mini and usedtext-embedding-small-3 as the\n",
      "embedding model.\n",
      "Retrieval-Augmented Generation (RAG) As a baseline, we treat the entire conversation history as a\n",
      "document collection and apply a standard RAG pipeline. We first segment each conversation into fixed-length\n",
      "chunks (128, 256, 512, 1024, 2048, 4096, and 8192 tokens), where 8192 is the maximum chunk size\n",
      "supported by our embedding model. All chunks are embedded using OpenAI’stext-embedding-small-3\n",
      "to ensure consistent vector quality across configurations. At query time, we retrieve the topk chunks by\n",
      "semantic similarity and concatenate them as context for answer generation. Throughout our experiments we\n",
      "set k∈{1,2}: with k=1 only the single most relevant chunk is used, and withk=2 the two most relevant\n",
      "chunks (up to 16384 tokens) are concatenated. We avoidk > 2 since the average conversation length (26000\n",
      "tokens) would be fully covered, negating the benefits of selective retrieval. By varying chunk size andk, we\n",
      "systematically evaluate RAG performance on long-term conversational memory tasks.\n",
      "Full-Context Processing We adopt a straightforward approach by passing the entire conversation history\n",
      "within the context window of the LLM. This method leverages the model’s inherent ability to process\n",
      "sequentialinformationwithoutadditionalarchitecturalcomponents. Whileconceptuallysimple,thisapproach\n",
      "faces practical limitations as conversation length increases, eventually increasing token cost and latency.\n",
      "Nevertheless, it establishes an important reference point for understanding the value of more sophisticated\n",
      "memory mechanisms compared to direct processing of available context.\n",
      "ProprietaryModels WeevaluateOpenAI’smemory3 featureavailableintheirChatGPTinterface,specifically\n",
      "using gpt-4o-mini for consistency. We ingest entireLOCOMO conversations with a prompt (see Appendix A)\n",
      "intosinglechatsessions,promptingmemorygenerationwithtimestamps,participantnames,andconversation\n",
      "2https://langchain-ai.github.io/langmem/\n",
      "3https://openai.com/index/memory-and-new-controls-for-chatgpt/\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "similar_docs = vector_store.similarity_search(\"LOCOMO\")\n",
    "\n",
    "for doc in similar_docs:\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88fe36a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context(prompt):\n",
    "    context = vector_store.similarity_search(prompt)\n",
    "    # print(context)\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "956ce939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='id9', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-04-29T01:11:16+00:00', 'author': '', 'keywords': '', 'moddate': '2025-04-29T01:11:16+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': './Mem0.pdf', 'total_pages': 23, 'page': 8, 'page_label': '9'}, page_content='Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory\\nTable 1:Performance comparison of memory-enabled systems across different question types in theLOCOMO dataset.\\nEvaluation metrics include F1 score (F1), BLEU-1 (B1), and LLM-as-a-Judge score (J), with higher values indicating\\nbetter performance.A-Mem∗ represents results from our re-run of A-Mem to generate LLM-as-a-Judge scores by setting\\ntemperature as 0.Mem0g indicates our proposed architecture enhanced with graph memory.Bold denotes the best\\nperformance for each metric across all methods. (↑) represents higher score is better.\\nMethod Single Hop Multi-Hop Open Domain Temporal\\nF1 ↑ B1 ↑ J↑ F1 ↑ B1 ↑ J↑ F1 ↑ B1 ↑ J↑ F1 ↑ B1 ↑ J↑\\nLoCoMo 25.02 19.75 – 12.04 11.16 – 40.36 29.05 – 18.41 14.77 –\\nReadAgent 9.15 6.48 – 5.31 5.12 – 9.67 7.66 – 12.60 8.87 –\\nMemoryBank5.00 4.77 – 5.56 5.94 – 6.61 5.16 – 9.68 6.99 –\\nMemGPT 26.65 17.72 – 9.15 7.44 – 41.04 34.34 – 25.52 19.44 –\\nA-Mem 27.02 20.09 – 12.14 12.00 – 44.65 37.06 – 45.85 36.67 –\\nA-Mem* 20.76 14.90 39.79±0.38 9.22 8.81 18.85±0.31 33.34 27.58 54.05±0.22 35.40 31.08 49.91±0.31\\nLangMem 35.51 26.86 62.23±0.75 26.0422.3247.92±0.47 40.91 33.63 71.12±0.20 30.75 25.84 23.43±0.39\\nZep 35.74 23.30 61.70±0.32 19.37 14.82 41.35±0.48 49.5638.9276.60±0.13 42.00 34.53 49.31±0.50\\nOpenAI 34.30 23.72 63.79±0.46 20.09 15.42 42.92±0.63 39.31 31.16 62.29±0.12 14.04 11.25 21.71±0.20\\nMem0 38.72 27.13 67.13±0.6528.6421.5851.15±0.31 47.65 38.72 72.93±0.11 48.9340.5155.51±0.34\\nMem0g 38.09 26.03 65.71±0.45 24.32 18.82 47.19±0.67 49.2740.3075.71±0.21 51.5540.2858.13±0.44\\ntext. These generated memories are then used as complete context for answering questions about each\\nconversation, intentionally granting the OpenAI approach privileged access to all memories rather than\\nonly question-relevant ones. This methodology accommodates the lack of external API access for selective\\nmemory retrieval in OpenAI’s system for benchmarking.\\nMemoryProviders WeincorporateZep(Rasmussenetal.,2025),amemorymanagementplatformdesigned\\nfor AI agents. Using their platform version, we conduct systematic evaluations across theLOCOMO dataset,\\nmaintaining temporal fidelity by preserving timestamp information alongside conversational content. This\\ntemporalanchoringensuresthattime-sensitivequeriescanbeaddressedthroughappropriatelycontextualized\\nmemory retrieval, particularly important for evaluating questions that require chronological awareness.\\nThis baseline represents an important commercial implementation of memory management specifically\\nengineered for AI agents.\\n4. Evaluation Results, Analysis and Discussion.\\n4.1. Performance Comparison Across Memory-Enabled Systems\\nTable1reportsF 1, B1 andJscoresforourtwoarchitectures— Mem0and Mem0g —againstasuiteofcompetitive\\nbaselines, asmentionedinSection3, onsingle -hop, multi-hop, open-domain, andtemporalquestions. Overall,\\nboth of our models set new state-of-the-art marks in all the three evaluation metrics for most question types.\\nSingle-Hop Question Performance Single-hop queries involve locating a single factual span contained\\nwithin one dialogue turn. Leveraging its dense memories in natural language text,Mem0 secures the strongest\\nresults:F1=38.72, B1=27.13, and J=67.13. Augmenting the natural language memories with graph memory\\n(Mem0g) yields marginal performance drop compared toMem0, indicating that relational structure provides\\nlimited utility when the retrieval target occupies a single turn. Among the existing baselines, the full-context\\nOpenAIrun attains the next-best J score, reflecting the benefits of retaining the entire conversation in context,\\nwhile LangMem and Zep both score around 8% relatively less against our models on J score. PreviousLOCOMO\\n9'),\n",
       " Document(id='id21', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-04-29T01:11:16+00:00', 'author': '', 'keywords': '', 'moddate': '2025-04-29T01:11:16+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': './Mem0.pdf', 'total_pages': 23, 'page': 20, 'page_label': '21'}, page_content='Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory\\nB. Algorithm\\nAlgorithm 1Memory Management System: Update Operations\\n1: Input: Set of retrieved memoriesF, Existing memory storeM = {m1, m2, . . . , mn}\\n2: Output: Updated memory storeM′\\n3: procedure Up dat e M e mory(F, M)\\n4: for each fact f ∈ F do\\n5: operation ← C l as s i f y Op e r at ion(f , M) ▷ Execute appropriate operation based on\\nclassification\\n6: if operation = ADDthen\\n7: id ← GenerateUniqueID()\\n8: M ← M ∪ {(id, f ,\"ADD\")} ▷ Add new fact with unique identifier\\n9: else if operation = UPDATEthen\\n10: mi ← FindRelatedMemory(f , M)\\n11: if InformationContent(f ) > InformationContent(mi)then\\n12: M ← (M \\\\ {mi})∪ {(idi, f ,\"UPDATE\")} ▷ Replace with richer information\\n13: end if\\n14: else if operation = DELETE then\\n15: mi ← FindContradictedMemory(f , M)\\n16: M ← M \\\\ {mi} ▷ Remove contradicted information\\n17: else if operation = NOOPthen\\n18: No operation performed ▷ Fact already exists or is irrelevant\\n19: end if\\n20: end for\\n21: return M\\n22: end procedure\\n23: function C l as s i f y Op e r at ion( f , M)\\n24: if ¬SemanticallySimilar(f , M)then\\n25: return ADD ▷ New information not present in memory\\n26: else ifContradicts(f , M)then\\n27: return DELETE ▷ Information conflicts with existing memory\\n28: else ifAugments(f , M)then\\n29: return UPDATE ▷ Enhances existing information in memory\\n30: else\\n31: return NOOP ▷ No change required\\n32: end if\\n33: end function\\nC. Selected Baselines\\nLoCoMo The LoCoMo framework implements a sophisticated memory pipeline that enables LLM agents to\\nmaintain coherent, long-term conversations. At its core, the system divides memory into short-term and\\nlong-term components. After each conversation session, agents generate summaries (stored as short-term\\nmemory) that distill key information from that interaction. Simultaneously, individual conversation turns are\\n21'),\n",
       " Document(id='id11', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-04-29T01:11:16+00:00', 'author': '', 'keywords': '', 'moddate': '2025-04-29T01:11:16+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': './Mem0.pdf', 'total_pages': 23, 'page': 10, 'page_label': '11'}, page_content='Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory\\nTable 2:Performance comparison of various baselines with proposed methods. Latency measurements show p50\\n(median) and p95 (95th percentile) values in seconds for both search time (time taken to fetch memories/chunks) and\\ntotal time (time to generate the complete response). Overall LLM-as-a-Judge score (J) represents the quality metric of\\nthe generated responses on the entireLOCOMO dataset.\\nMethod\\nLatency (seconds) Overall\\nJSearch Total\\nK chunk size/\\nmemory tokens p50 p95 p50 p95\\nRAG\\n1\\n128 0.281 0.823 0.774 1.825 47.77 ± 0.23%\\n256 0.251 0.710 0.745 1.628 50.15 ± 0.16%\\n512 0.240 0.639 0.772 1.710 46.05 ± 0.14%\\n1024 0.240 0.723 0.821 1.957 40.74 ± 0.17%\\n2048 0.255 0.752 0.996 2.182 37.93 ± 0.12%\\n4096 0.254 0.719 1.093 2.711 36.84 ± 0.17%\\n8192 0.279 0.838 1.396 4.416 44.53 ± 0.13%\\n2\\n128 0.267 0.624 0.766 1.829 59.56 ± 0.19%\\n256 0.255 0.699 0.802 1.907 60.97 ± 0.20%\\n512 0.247 0.746 0.829 1.729 58.19 ± 0.18%\\n1024 0.238 0.702 0.860 1.850 50.68 ± 0.13%\\n2048 0.261 0.829 1.101 2.791 48.57 ± 0.22%\\n4096 0.266 0.944 1.451 4.822 51.79 ± 0.15%\\n8192 0.288 1.124 2.312 9.942 60.53 ± 0.16%\\nFull-context 26031 - - 9.870 17.117 72.90 ± 0.19%\\nA-Mem 2520 0.668 1.485 1.410 4.374 48.38 ± 0.15%\\nLangMem 127 17.99 59.82 18.53 60.40 58.10 ± 0.21%\\nZep 3911 0.513 0.778 1.292 2.926 65.99 ± 0.16%\\nOpenAI 4437 - - 0.466 0.889 52.90 ± 0.14%\\nMem0 1764 0.148 0.200 0.708 1.440 66.88 ± 0.15%\\nMem0g 3616 0.476 0.657 1.091 2.590 68.44 ± 0.17%\\nexpected relational advantages ofMem0g do not translate into better outcomes here, suggesting potential\\noverhead or redundancy when navigating more intricate graph structures in multi-step reasoning scenarios.\\nIn temporal reasoning, Mem0g substantially outperforms other methods, validating that structured\\nrelational graphs excel in capturing chronological relationships and event sequences. The presence of explicit\\nrelational context significantly enhancesMem0g’s temporal coherence, outperformingMem0’s dense memory\\nstorage and highlighting the importance of precise relational representations when tracking temporally\\nsensitive information. Open-domain performance further reinforces the value of relational modeling.Mem0g,\\nbenefiting from the relational clarity of graph-based memory, closely competes with the top-performing\\nbaseline (Zep). This competitive result underscoresMem0g’s robustness in integrating external knowledge\\nthrough relational clarity, suggesting an optimal synergy between structured memory and open-domain\\ninformation synthesis.\\n11'),\n",
       " Document(id='id8', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-04-29T01:11:16+00:00', 'author': '', 'keywords': '', 'moddate': '2025-04-29T01:11:16+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': './Mem0.pdf', 'total_pages': 23, 'page': 7, 'page_label': '8'}, page_content='Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory\\nrobustframeworkforevaluatingtheeffectivenessofdifferentmemoryarchitecturesacrossvariousdimensions,\\nincluding factual accuracy, computational efficiency, and scalability to extended conversations. Where\\napplicable, unless otherwise specified, we set the temperature to 0 to ensure the runs are as reproducible as\\npossible.\\nEstablished LOCOMO Benchmarks We first establish a comparative foundation by evaluating previously\\nbenchmarked methods on theLOCOMO dataset. These include five established approaches: LoCoMo (Maha-\\nrana et al., 2024), ReadAgent (Lee et al., 2024), MemoryBank (Zhong et al., 2024), MemGPT (Packer et al.,\\n2023), and A-Mem (Xu et al., 2025). These established benchmarks not only provide direct comparison\\npoints with published results but also represent the evolution of conversational memory architectures across\\ndifferent algorithmic paradigms. For our evaluation, we select the metrics wheregpt-4o-mini was used\\nfor the evaluation. More details about these benchmarks are mentioned in Appendix C.\\nOpen-Source Memory Solutions Our second category consists of promising open-source memory architec-\\ntures such as LangMem2 (Hot Path) that have demonstrated effectiveness in related conversational tasks but\\nhave not yet been evaluated on theLOCOMO dataset. By adapting these systems to our evaluation framework,\\nwe broaden the comparative landscape and identify potential alternative approaches that may offer competi-\\ntive performance. We initialized the LLM withgpt-4o-mini and usedtext-embedding-small-3 as the\\nembedding model.\\nRetrieval-Augmented Generation (RAG) As a baseline, we treat the entire conversation history as a\\ndocument collection and apply a standard RAG pipeline. We first segment each conversation into fixed-length\\nchunks (128, 256, 512, 1024, 2048, 4096, and 8192 tokens), where 8192 is the maximum chunk size\\nsupported by our embedding model. All chunks are embedded using OpenAI’stext-embedding-small-3\\nto ensure consistent vector quality across configurations. At query time, we retrieve the topk chunks by\\nsemantic similarity and concatenate them as context for answer generation. Throughout our experiments we\\nset k∈{1,2}: with k=1 only the single most relevant chunk is used, and withk=2 the two most relevant\\nchunks (up to 16384 tokens) are concatenated. We avoidk > 2 since the average conversation length (26000\\ntokens) would be fully covered, negating the benefits of selective retrieval. By varying chunk size andk, we\\nsystematically evaluate RAG performance on long-term conversational memory tasks.\\nFull-Context Processing We adopt a straightforward approach by passing the entire conversation history\\nwithin the context window of the LLM. This method leverages the model’s inherent ability to process\\nsequentialinformationwithoutadditionalarchitecturalcomponents. Whileconceptuallysimple,thisapproach\\nfaces practical limitations as conversation length increases, eventually increasing token cost and latency.\\nNevertheless, it establishes an important reference point for understanding the value of more sophisticated\\nmemory mechanisms compared to direct processing of available context.\\nProprietaryModels WeevaluateOpenAI’smemory3 featureavailableintheirChatGPTinterface,specifically\\nusing gpt-4o-mini for consistency. We ingest entireLOCOMO conversations with a prompt (see Appendix A)\\nintosinglechatsessions,promptingmemorygenerationwithtimestamps,participantnames,andconversation\\n2https://langchain-ai.github.io/langmem/\\n3https://openai.com/index/memory-and-new-controls-for-chatgpt/\\n8')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = get_context(\"LOCOMO\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c8cdbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_document_list(docs):\n",
    "    formatted = \"\"\n",
    "    for doc in docs:\n",
    "        formatted += doc.page_content\n",
    "    # print(formatted)\n",
    "    return formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90c576d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory\\nTable 1:Performance comparison of memory-enabled systems across different question types in theLOCOMO dataset.\\nEvaluation metrics include F1 score (F1), BLEU-1 (B1), and LLM-as-a-Judge score (J), with higher values indicating\\nbetter performance.A-Mem∗ represents results from our re-run of A-Mem to generate LLM-as-a-Judge scores by setting\\ntemperature as 0.Mem0g indicates our proposed architecture enhanced with graph memory.Bold denotes the best\\nperformance for each metric across all methods. (↑) represents higher score is better.\\nMethod Single Hop Multi-Hop Open Domain Temporal\\nF1 ↑ B1 ↑ J↑ F1 ↑ B1 ↑ J↑ F1 ↑ B1 ↑ J↑ F1 ↑ B1 ↑ J↑\\nLoCoMo 25.02 19.75 – 12.04 11.16 – 40.36 29.05 – 18.41 14.77 –\\nReadAgent 9.15 6.48 – 5.31 5.12 – 9.67 7.66 – 12.60 8.87 –\\nMemoryBank5.00 4.77 – 5.56 5.94 – 6.61 5.16 – 9.68 6.99 –\\nMemGPT 26.65 17.72 – 9.15 7.44 – 41.04 34.34 – 25.52 19.44 –\\nA-Mem 27.02 20.09 – 12.14 12.00 – 44.65 37.06 – 45.85 36.67 –\\nA-Mem* 20.76 14.90 39.79±0.38 9.22 8.81 18.85±0.31 33.34 27.58 54.05±0.22 35.40 31.08 49.91±0.31\\nLangMem 35.51 26.86 62.23±0.75 26.0422.3247.92±0.47 40.91 33.63 71.12±0.20 30.75 25.84 23.43±0.39\\nZep 35.74 23.30 61.70±0.32 19.37 14.82 41.35±0.48 49.5638.9276.60±0.13 42.00 34.53 49.31±0.50\\nOpenAI 34.30 23.72 63.79±0.46 20.09 15.42 42.92±0.63 39.31 31.16 62.29±0.12 14.04 11.25 21.71±0.20\\nMem0 38.72 27.13 67.13±0.6528.6421.5851.15±0.31 47.65 38.72 72.93±0.11 48.9340.5155.51±0.34\\nMem0g 38.09 26.03 65.71±0.45 24.32 18.82 47.19±0.67 49.2740.3075.71±0.21 51.5540.2858.13±0.44\\ntext. These generated memories are then used as complete context for answering questions about each\\nconversation, intentionally granting the OpenAI approach privileged access to all memories rather than\\nonly question-relevant ones. This methodology accommodates the lack of external API access for selective\\nmemory retrieval in OpenAI’s system for benchmarking.\\nMemoryProviders WeincorporateZep(Rasmussenetal.,2025),amemorymanagementplatformdesigned\\nfor AI agents. Using their platform version, we conduct systematic evaluations across theLOCOMO dataset,\\nmaintaining temporal fidelity by preserving timestamp information alongside conversational content. This\\ntemporalanchoringensuresthattime-sensitivequeriescanbeaddressedthroughappropriatelycontextualized\\nmemory retrieval, particularly important for evaluating questions that require chronological awareness.\\nThis baseline represents an important commercial implementation of memory management specifically\\nengineered for AI agents.\\n4. Evaluation Results, Analysis and Discussion.\\n4.1. Performance Comparison Across Memory-Enabled Systems\\nTable1reportsF 1, B1 andJscoresforourtwoarchitectures— Mem0and Mem0g —againstasuiteofcompetitive\\nbaselines, asmentionedinSection3, onsingle -hop, multi-hop, open-domain, andtemporalquestions. Overall,\\nboth of our models set new state-of-the-art marks in all the three evaluation metrics for most question types.\\nSingle-Hop Question Performance Single-hop queries involve locating a single factual span contained\\nwithin one dialogue turn. Leveraging its dense memories in natural language text,Mem0 secures the strongest\\nresults:F1=38.72, B1=27.13, and J=67.13. Augmenting the natural language memories with graph memory\\n(Mem0g) yields marginal performance drop compared toMem0, indicating that relational structure provides\\nlimited utility when the retrieval target occupies a single turn. Among the existing baselines, the full-context\\nOpenAIrun attains the next-best J score, reflecting the benefits of retaining the entire conversation in context,\\nwhile LangMem and Zep both score around 8% relatively less against our models on J score. PreviousLOCOMO\\n9Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory\\nB. Algorithm\\nAlgorithm 1Memory Management System: Update Operations\\n1: Input: Set of retrieved memoriesF, Existing memory storeM = {m1, m2, . . . , mn}\\n2: Output: Updated memory storeM′\\n3: procedure Up dat e M e mory(F, M)\\n4: for each fact f ∈ F do\\n5: operation ← C l as s i f y Op e r at ion(f , M) ▷ Execute appropriate operation based on\\nclassification\\n6: if operation = ADDthen\\n7: id ← GenerateUniqueID()\\n8: M ← M ∪ {(id, f ,\"ADD\")} ▷ Add new fact with unique identifier\\n9: else if operation = UPDATEthen\\n10: mi ← FindRelatedMemory(f , M)\\n11: if InformationContent(f ) > InformationContent(mi)then\\n12: M ← (M \\\\ {mi})∪ {(idi, f ,\"UPDATE\")} ▷ Replace with richer information\\n13: end if\\n14: else if operation = DELETE then\\n15: mi ← FindContradictedMemory(f , M)\\n16: M ← M \\\\ {mi} ▷ Remove contradicted information\\n17: else if operation = NOOPthen\\n18: No operation performed ▷ Fact already exists or is irrelevant\\n19: end if\\n20: end for\\n21: return M\\n22: end procedure\\n23: function C l as s i f y Op e r at ion( f , M)\\n24: if ¬SemanticallySimilar(f , M)then\\n25: return ADD ▷ New information not present in memory\\n26: else ifContradicts(f , M)then\\n27: return DELETE ▷ Information conflicts with existing memory\\n28: else ifAugments(f , M)then\\n29: return UPDATE ▷ Enhances existing information in memory\\n30: else\\n31: return NOOP ▷ No change required\\n32: end if\\n33: end function\\nC. Selected Baselines\\nLoCoMo The LoCoMo framework implements a sophisticated memory pipeline that enables LLM agents to\\nmaintain coherent, long-term conversations. At its core, the system divides memory into short-term and\\nlong-term components. After each conversation session, agents generate summaries (stored as short-term\\nmemory) that distill key information from that interaction. Simultaneously, individual conversation turns are\\n21Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory\\nTable 2:Performance comparison of various baselines with proposed methods. Latency measurements show p50\\n(median) and p95 (95th percentile) values in seconds for both search time (time taken to fetch memories/chunks) and\\ntotal time (time to generate the complete response). Overall LLM-as-a-Judge score (J) represents the quality metric of\\nthe generated responses on the entireLOCOMO dataset.\\nMethod\\nLatency (seconds) Overall\\nJSearch Total\\nK chunk size/\\nmemory tokens p50 p95 p50 p95\\nRAG\\n1\\n128 0.281 0.823 0.774 1.825 47.77 ± 0.23%\\n256 0.251 0.710 0.745 1.628 50.15 ± 0.16%\\n512 0.240 0.639 0.772 1.710 46.05 ± 0.14%\\n1024 0.240 0.723 0.821 1.957 40.74 ± 0.17%\\n2048 0.255 0.752 0.996 2.182 37.93 ± 0.12%\\n4096 0.254 0.719 1.093 2.711 36.84 ± 0.17%\\n8192 0.279 0.838 1.396 4.416 44.53 ± 0.13%\\n2\\n128 0.267 0.624 0.766 1.829 59.56 ± 0.19%\\n256 0.255 0.699 0.802 1.907 60.97 ± 0.20%\\n512 0.247 0.746 0.829 1.729 58.19 ± 0.18%\\n1024 0.238 0.702 0.860 1.850 50.68 ± 0.13%\\n2048 0.261 0.829 1.101 2.791 48.57 ± 0.22%\\n4096 0.266 0.944 1.451 4.822 51.79 ± 0.15%\\n8192 0.288 1.124 2.312 9.942 60.53 ± 0.16%\\nFull-context 26031 - - 9.870 17.117 72.90 ± 0.19%\\nA-Mem 2520 0.668 1.485 1.410 4.374 48.38 ± 0.15%\\nLangMem 127 17.99 59.82 18.53 60.40 58.10 ± 0.21%\\nZep 3911 0.513 0.778 1.292 2.926 65.99 ± 0.16%\\nOpenAI 4437 - - 0.466 0.889 52.90 ± 0.14%\\nMem0 1764 0.148 0.200 0.708 1.440 66.88 ± 0.15%\\nMem0g 3616 0.476 0.657 1.091 2.590 68.44 ± 0.17%\\nexpected relational advantages ofMem0g do not translate into better outcomes here, suggesting potential\\noverhead or redundancy when navigating more intricate graph structures in multi-step reasoning scenarios.\\nIn temporal reasoning, Mem0g substantially outperforms other methods, validating that structured\\nrelational graphs excel in capturing chronological relationships and event sequences. The presence of explicit\\nrelational context significantly enhancesMem0g’s temporal coherence, outperformingMem0’s dense memory\\nstorage and highlighting the importance of precise relational representations when tracking temporally\\nsensitive information. Open-domain performance further reinforces the value of relational modeling.Mem0g,\\nbenefiting from the relational clarity of graph-based memory, closely competes with the top-performing\\nbaseline (Zep). This competitive result underscoresMem0g’s robustness in integrating external knowledge\\nthrough relational clarity, suggesting an optimal synergy between structured memory and open-domain\\ninformation synthesis.\\n11Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory\\nrobustframeworkforevaluatingtheeffectivenessofdifferentmemoryarchitecturesacrossvariousdimensions,\\nincluding factual accuracy, computational efficiency, and scalability to extended conversations. Where\\napplicable, unless otherwise specified, we set the temperature to 0 to ensure the runs are as reproducible as\\npossible.\\nEstablished LOCOMO Benchmarks We first establish a comparative foundation by evaluating previously\\nbenchmarked methods on theLOCOMO dataset. These include five established approaches: LoCoMo (Maha-\\nrana et al., 2024), ReadAgent (Lee et al., 2024), MemoryBank (Zhong et al., 2024), MemGPT (Packer et al.,\\n2023), and A-Mem (Xu et al., 2025). These established benchmarks not only provide direct comparison\\npoints with published results but also represent the evolution of conversational memory architectures across\\ndifferent algorithmic paradigms. For our evaluation, we select the metrics wheregpt-4o-mini was used\\nfor the evaluation. More details about these benchmarks are mentioned in Appendix C.\\nOpen-Source Memory Solutions Our second category consists of promising open-source memory architec-\\ntures such as LangMem2 (Hot Path) that have demonstrated effectiveness in related conversational tasks but\\nhave not yet been evaluated on theLOCOMO dataset. By adapting these systems to our evaluation framework,\\nwe broaden the comparative landscape and identify potential alternative approaches that may offer competi-\\ntive performance. We initialized the LLM withgpt-4o-mini and usedtext-embedding-small-3 as the\\nembedding model.\\nRetrieval-Augmented Generation (RAG) As a baseline, we treat the entire conversation history as a\\ndocument collection and apply a standard RAG pipeline. We first segment each conversation into fixed-length\\nchunks (128, 256, 512, 1024, 2048, 4096, and 8192 tokens), where 8192 is the maximum chunk size\\nsupported by our embedding model. All chunks are embedded using OpenAI’stext-embedding-small-3\\nto ensure consistent vector quality across configurations. At query time, we retrieve the topk chunks by\\nsemantic similarity and concatenate them as context for answer generation. Throughout our experiments we\\nset k∈{1,2}: with k=1 only the single most relevant chunk is used, and withk=2 the two most relevant\\nchunks (up to 16384 tokens) are concatenated. We avoidk > 2 since the average conversation length (26000\\ntokens) would be fully covered, negating the benefits of selective retrieval. By varying chunk size andk, we\\nsystematically evaluate RAG performance on long-term conversational memory tasks.\\nFull-Context Processing We adopt a straightforward approach by passing the entire conversation history\\nwithin the context window of the LLM. This method leverages the model’s inherent ability to process\\nsequentialinformationwithoutadditionalarchitecturalcomponents. Whileconceptuallysimple,thisapproach\\nfaces practical limitations as conversation length increases, eventually increasing token cost and latency.\\nNevertheless, it establishes an important reference point for understanding the value of more sophisticated\\nmemory mechanisms compared to direct processing of available context.\\nProprietaryModels WeevaluateOpenAI’smemory3 featureavailableintheirChatGPTinterface,specifically\\nusing gpt-4o-mini for consistency. We ingest entireLOCOMO conversations with a prompt (see Appendix A)\\nintosinglechatsessions,promptingmemorygenerationwithtimestamps,participantnames,andconversation\\n2https://langchain-ai.github.io/langmem/\\n3https://openai.com/index/memory-and-new-controls-for-chatgpt/\\n8'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_document_list(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "178a16c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"\"\"\n",
    "        You are Mohit and you are AI expert,\n",
    "        you have access to all the docs and research paper.\n",
    "        You will get a prompt and some context, go through the context\n",
    "        and explain that concept to the user.\n",
    "\n",
    "        Your tone should be friendly. Do not use emojis.\n",
    "        RESPOND IN PLAIN TEXT, do not use MarkDown syntax.\n",
    "        \"\"\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1b8319c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "\n",
    "def print_llm_response(prompt):\n",
    "    similar_docs = get_context(f\"PROMPT: {prompt}. Explain!\")\n",
    "    formatted_context = format_document_list(similar_docs[:3])\n",
    "\n",
    "    messages.append(\n",
    "        (\"human\", f\"\"\"PROMPT: {prompt} \\nCONTEXT: {formatted_context}\"\"\"))\n",
    "    \n",
    "    if len(messages) > 7:\n",
    "        messages = [messages[0]] + messages[-6:]\n",
    "    \n",
    "    print(f\"\"\"PROMPT: {prompt} \\nCONTEXT: {formatted_context}\"\"\")\n",
    "\n",
    "    llm = ChatGroq(\n",
    "        model=\"groq/compound-mini\",\n",
    "        temperature=0,\n",
    "        max_tokens=None,\n",
    "        timeout=None,\n",
    "        max_retries=2,\n",
    "        streaming=True\n",
    "    )\n",
    "\n",
    "    response = \"\"\n",
    "\n",
    "    for chunk in llm.stream(messages):\n",
    "        response += chunk.content\n",
    "        print(chunk.content, end=\"\", flush=True)\n",
    "\n",
    "    messages.append((\"assistant\", response))\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "47a34377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_text(filename, content):\n",
    "    with open(filename, 'w', encoding='utf-8') as file:\n",
    "        file.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6c053e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT: What is mem0? \n",
      "CONTEXT: Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory\n",
      "P rom p t Te m p l at e f or Re s u lt s G e n e r at ion (M e m 0g )\n",
      "(same as previous )\n",
      "# APPROACH (Think step by step):\n",
      "1. First, examine all memories that contain information related to the question\n",
      "2. Examine the timestamps and content of these memories carefully\n",
      "3. Look for explicit mentions of dates, times, locations, or events that answer the\n",
      "question\n",
      "4. If the answer requires calculation (e.g., converting relative time references), show\n",
      "your work\n",
      "5. Analyze the knowledge graph relations to understand the user’s knowledge context\n",
      "6. Formulate a precise, concise answer based solely on the evidence in the memories\n",
      "7. Double-check that your answer directly addresses the question asked\n",
      "8. Ensure your final answer is specific and avoids vague time references\n",
      "Memories for user {speaker_1_user_id}:\n",
      "{speaker_1_memories}\n",
      "Relations for user {speaker_1_user_id}:\n",
      "{speaker_1_graph_memories}\n",
      "Memories for user {speaker_2_user_id}:\n",
      "{speaker_2_memories}\n",
      "Relations for user {speaker_2_user_id}:\n",
      "{speaker_2_graph_memories}\n",
      "Question: {question}\n",
      "Answer:\n",
      "P rom p t Te m p l at e f or Op e n A I C h at G P T\n",
      "Can you please extract relevant information from this conversation and create memory\n",
      "entries for each user mentioned? Please store these memories in your knowledge base in\n",
      "addition to the timestamp provided for future reference and personalized interactions.\n",
      "(1:56 pm on 8 May, 2023) Caroline: Hey Mel! Good to see you! How have you been?\n",
      "(1:56 pm on 8 May, 2023) Melanie: Hey Caroline! Good to see you! I’m swamped with the\n",
      "kids & work. What’s up with you? Anything new?\n",
      "(1:56 pm on 8 May, 2023) Caroline: I went to a LGBTQ support group yesterday and it was so\n",
      "powerful.\n",
      "...\n",
      "20Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory\n",
      "Figure 2:Architectural overview of theMem0 system showing extraction and update phase. The extraction phase\n",
      "processes messages and historical context to create new memories. The update phase evaluates these extracted\n",
      "memories against similar existing ones, applying appropriate operations through a Tool Call mechanism. The database\n",
      "serves as the central repository, providing context for processing and storing updated memories.\n",
      "encapsulates the semantic content of the entire conversation history, and(2) a sequence of recent messages\n",
      "{mt−m, mt−m+1, ..., mt−2}from the conversation history, wherem is a hyperparameter controlling the recency\n",
      "window. To support context-aware memory extraction, we implement an asynchronous summary generation\n",
      "module that periodically refreshes the conversation summary. This component operates independently of the\n",
      "main processing pipeline, ensuring that memory extraction consistently benefits from up-to-date contextual\n",
      "information without introducing processing delays. WhileS provides global thematic understanding across\n",
      "the entire conversation, the recent message sequence offers granular temporal context that may contain\n",
      "relevant details not consolidated in the summary. This dual contextual information, combined with the new\n",
      "message pair, forms a comprehensive promptP = (S, {mt−m, ..., mt−2}, mt−1, mt)for an extraction function\n",
      "ϕ implemented via an LLM. The functionϕ(P)then extracts a set of salient memoriesΩ = {ω1, ω2, ..., ωn}\n",
      "specifically from the new exchange while maintaining awareness of the conversation’s broader context,\n",
      "resulting in candidate facts for potential inclusion in the knowledge base.\n",
      "Following extraction, theupdate phaseevaluates each candidate fact against existing memories to\n",
      "maintain consistency and avoid redundancy. This phase determines the appropriate memory management\n",
      "operation for each extracted factωi ∈ Ω. Algorithm 1, mentioned in Appendix B, illustrates this process. For\n",
      "each fact, the system first retrieves the tops semantically similar memories using vector embeddings from the\n",
      "database. These retrieved memories, along with the candidate fact, are then presented to the LLM through\n",
      "a function-calling interface we refer to as a ‘tool call.’ The LLM itself determines which of four distinct\n",
      "operations to execute:ADD for creation of new memories when no semantically equivalent memory exists;\n",
      "UPDATE for augmentation of existing memories with complementary information;DELETE for removal of\n",
      "memories contradicted by new information; andNOOP when the candidate fact requires no modification to\n",
      "the knowledge base. Rather than using a separate classifier, we leverage the LLM’s reasoning capabilities\n",
      "to directly select the appropriate operation based on the semantic relationship between the candidate fact\n",
      "and existing memories. Following this determination, the system executes the provided operations, thereby\n",
      "maintaining knowledge base coherence and temporal consistency.\n",
      "4Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory\n",
      "P rom p t Te m p l at e f or Re s u lt s G e n e r at ion (M e m 0)\n",
      "You are an intelligent memory assistant tasked with retrieving accurate information from\n",
      "conversation memories.\n",
      "# CONTEXT:\n",
      "You have access to memories from two speakers in a conversation. These memories contain\n",
      "timestamped information that may be relevant to answering the question.\n",
      "# INSTRUCTIONS:\n",
      "1. Carefully analyze all provided memories from both speakers\n",
      "2. Pay special attention to the timestamps to determine the answer\n",
      "3. If the question asks about a specific event or fact, look for direct evidence in the\n",
      "memories\n",
      "4. If the memories contain contradictory information, prioritize the most recent memory\n",
      "5. If there is a question about time references (like \"last year\", \"two months ago\",\n",
      "etc.), calculate the actual date based on the memory timestamp. For example, if a memory\n",
      "from 4 May 2022 mentions \"went to India last year,\" then the trip occurred in 2021.\n",
      "6. Always convert relative time references to specific dates, months, or years. For\n",
      "example, convert \"last year\" to \"2022\" or \"two months ago\" to \"March 2023\" based on the\n",
      "memory timestamp. Ignore the reference while answering the question.\n",
      "7. Focus only on the content of the memories from both speakers. Do not confuse character\n",
      "names mentioned in memories with the actual users who created those memories.\n",
      "8. The answer should be less than 5-6 words.\n",
      "# APPROACH (Think step by step):\n",
      "1. First, examine all memories that contain information related to the question\n",
      "2. Examine the timestamps and content of these memories carefully\n",
      "3. Look for explicit mentions of dates, times, locations, or events that answer the\n",
      "question\n",
      "4. If the answer requires calculation (e.g., converting relative time references), show\n",
      "your work\n",
      "5. Formulate a precise, concise answer based solely on the evidence in the memories\n",
      "6. Double-check that your answer directly addresses the question asked\n",
      "7. Ensure your final answer is specific and avoids vague time references\n",
      "Memories for user {speaker_1_user_id}:\n",
      "{speaker_1_memories}\n",
      "Memories for user {speaker_2_user_id}:\n",
      "{speaker_2_memories}\n",
      "Question: {question}\n",
      "Answer:\n",
      "19\n",
      "Mem0 is a framework designed to give AI agents a production‑ready, scalable long‑term memory. It works in two main phases.  \n",
      "\n",
      "In the **extraction phase**, the system processes new messages together with a summary of the entire conversation and a short window of recent messages. Using a large language model, it extracts salient facts—called “memories”—that capture the important information from the latest exchange while staying aware of the broader context.  \n",
      "\n",
      "In the **update phase**, each newly extracted fact is compared against existing memories stored in a central vector‑based database. The system retrieves the most similar memories and, via a tool‑call interface, lets the LLM decide which of four operations to apply:  \n",
      "\n",
      "- **ADD** – create a new memory when no equivalent exists,  \n",
      "- **UPDATE** – augment an existing memory with complementary details,  \n",
      "- **DELETE** – remove a memory that is contradicted by new information,  \n",
      "- **NOOP** – leave the knowledge base unchanged when the fact adds nothing new.  \n",
      "\n",
      "By continuously extracting, evaluating, and managing memories, Mem0 maintains a coherent, up‑to‑date knowledge base that an AI agent can query to produce context‑aware, consistent responses over long interactions. The architecture is built to handle large volumes of conversational data efficiently, making it suitable for real‑world deployment of memory‑enhanced agents."
     ]
    }
   ],
   "source": [
    "response = print_llm_response(\"What is mem0?\")\n",
    "save_text(\"AI_Response.md\", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maventic_ai_101",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
